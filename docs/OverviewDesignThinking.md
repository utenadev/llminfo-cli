# Overview: Design Thinking for Human-LLM Collaboration

This document outlines the design philosophy for building applications specifically when collaborating with Large Language Models (LLMs).
In this workflow, the codebase and documentation serve not just as records for humans, but as **Context and Prompts for the AI Agent**.

## 1. The Core Philosophy: "Codebase as Context"

When working with LLMs, the clarity of your project structure directly impacts the quality of the AI's output.
**Ambiguity in design leads to hallucinations in code.**

### 1.1 Documentation as System Prompts
Instead of vague instructions, use markdown files to anchor the LLM's understanding.

- **`SPEC.md` (The "What")**:
    - Acts as the primary instruction set.
    - **For LLMs**: If a requirement isn't here, the LLM will guess (and often guess wrong).
    - **Rule**: Update this file *before* asking the LLM to implement complex features. It serves as the source of truth.
- **`BLUEPRINT.md` (The "How")**:
    - Defines the architectural constraints.
    - **For LLMs**: Prevents the AI from inventing new patterns or libraries inconsistent with the project.
    - **Rule**: Explicitly list selected libraries and directory structures here to constrain the search space.

### 1.2 Modular Architecture for Context Windows
LLMs have finite context windows. Huge files degrade performance and reasoning capability.

- **Small Context Principle**:
    - Keep files focused (Single Responsibility Principle).
    - An LLM can reason better about a 100-line file than a 2000-line file.
- **Explicit Interfaces**:
    - Define clear boundaries between modules. This allows you to feed only relevant files (e.g., `interface.py` and `implementation.py`) to the LLM during a chat session, reducing noise.

## 2. Design Principles for AI Safety

### 2.1 Constraints over Creativity
LLMs are naturally creative/generative. In software engineering, we want determinism.

- **Strict Configuration**:
    - Do not allow the LLM to hardcode magic numbers or strings.
    - **Design Pattern**: Force all configuration into Pydantic models or YAML files. This separates "Logic" (generated by LLM) from "Settings" (controlled by Human).
- **Fail-Fast Design**:
    - Design systems that crash loudly on error rather than failing silently. This provides immediate feedback (tracebacks) that the LLM can analyze to fix itself.

## 3. Project Scale & LLM Interaction

Adjust the density of your "Context" based on project size.

### Level 1: Script / Prototype
- **Goal**: Speed.
- **LLM Context**: Single file.
- **Design**: Put the "Spec" in the file docstring.
    ```python
    """
    SPEC:
    1. Read CSV from input.
    2. Summarize column 'price'.
    3. Output to stdout.
    """
    ```

### Level 2: Tool / Utility (Standard)
- **Goal**: Maintainability & Reliability.
- **LLM Context**: `docs/SPEC.md`, `pyproject.toml`, `Taskfile.yml`.
- **Design**: Clear separation of `main.py` (CLI), `core/` (Logic), and `schemas/` (Data).
- **Workflow**: Human writes `SPEC.md` -> LLM implements -> Human verifies.

### Level 3: Platform / Complex System
- **Goal**: Scalability & Teamwork.
- **LLM Context**: Segmented specifications (e.g., `docs/specs/auth.md`, `docs/specs/billing.md`).
- **Design**: Domain-Driven Design (DDD). Interfaces defined first.
- **Workflow**:
    1. Human defines Interface/Abstract Base Class.
    2. LLM generates implementation.
    3. LLM generates tests against the interface.

## 4. The Iteration Loop
1. **Define**: Update `SPEC.md` or `BLUEPRINT.md`.
2. **Generate**: Ask the agent to implement based on the docs.
3. **Verify**: Run `task check` (Lint/Test).
4. **Refine**: Paste the error output back to the agent. **Do not fix it manually unless stuck.** Let the agent learn the constraints.